{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine data --> Classification\n",
    "wine_data = pd.read_csv('WineQT.csv')\n",
    "wine_data.drop_duplicates(inplace=True)\n",
    "wine_data = wine_data.drop(columns=['Id'])\n",
    "# 1143 samples, 12 attributes including quality which is to be determined (3-8)\n",
    "\n",
    "# Split the data into attributes and labels\n",
    "cX = wine_data.iloc[:,wine_data.columns != 'quality'].to_numpy()\n",
    "cY = wine_data['quality'].map({3:0, 4:0, 5:0, 6:1, 7:1, 8:1}).to_numpy()\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "cX = imputer.fit_transform(cX)\n",
    "\n",
    "# Apply Normalization to the attributes\n",
    "scaler = MinMaxScaler()\n",
    "cX = scaler.fit_transform(cX)\n",
    "\n",
    "# Apply Standardization to the attributes\n",
    "scaler = StandardScaler()\n",
    "cX = scaler.fit_transform(cX)\n",
    "\n",
    "wine_data = list(zip(cX, cY))\n",
    "cx_train, cx_test, cy_train, cy_test = train_test_split(cX, cY, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing data --> Regression\n",
    "housing_data = pd.read_csv('HousingData.csv')\n",
    "housing_data.drop_duplicates(inplace=True)\n",
    "# 506 samples, 14 attributes including MEDV which is to be determined (real)\n",
    "\n",
    "# Split the data into attributes and labels\n",
    "rX = housing_data.iloc[:,housing_data.columns != 'MEDV']\n",
    "rY = np.array(housing_data['MEDV']).reshape(-1, 1)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "rX = imputer.fit_transform(rX)\n",
    "\n",
    "# Apply Normalization to the attributes\n",
    "scaler = MinMaxScaler()\n",
    "rX = scaler.fit_transform(rX)\n",
    "\n",
    "# Apply Standardization to the attributes\n",
    "scaler = StandardScaler()\n",
    "rX = scaler.fit_transform(rX)\n",
    "\n",
    "housing_data = list(zip(rX, rY))\n",
    "rx_train, rx_test, ry_train, ry_test = train_test_split(rX, rY, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_trees, max_depth=None):\n",
    "        self.trees = []\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        for _ in range(self.n_trees):\n",
    "            idx = np.random.choice(len(x_train), len(y_train), replace=True)\n",
    "            x, y = x_train[idx], y_train[idx]\n",
    "\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            tree.fit(x, y)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_pred = np.array([tree.predict(x_test) for tree in self.trees])\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=0, arr=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7510917030567685\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(3)\n",
    "model.fit(cx_train, cy_train)\n",
    "y_pred = model.predict(cx_test)\n",
    "accuracy = np.mean(cy_test == y_pred)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor:\n",
    "    def __init__(self, n_trees, max_depth=None):\n",
    "        self.trees = []\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        for _ in range(self.n_trees):\n",
    "            idx = np.random.choice(len(x_train), len(y_train), replace=True)\n",
    "            x, y = x_train[idx], y_train[idx]\n",
    "\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(x, y)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_pred = np.array([tree.predict(x_test) for tree in self.trees])\n",
    "        return np.mean(y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  9.0289651416122\n",
      "r2 score:  0.894497505410796\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(3)\n",
    "model.fit(rx_train, ry_train)\n",
    "y_pred = model.predict(rx_test)\n",
    "print('mse: ', mean_squared_error(ry_test, y_pred))\n",
    "print('r2 score: ', r2_score(ry_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingClassifier():\n",
    "    def __init__(self, n_est=30, learn_rate=0.01, max_depth=8):\n",
    "        self.n_est = n_est\n",
    "        self.learn_rate = learn_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "        self.weights = []\n",
    "\n",
    "    def get_gradient(self, X, y):\n",
    "        y_pred = 0\n",
    "        for w, est in zip(self.weights, self.models):\n",
    "            y_pred += self.learn_rate * w * est.predict(X)\n",
    "        return y - 1 / (1 + np.exp(-y_pred))\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        self.base_estimator = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "        self.base_estimator.fit(X, y)\n",
    "        self.models.append(self.base_estimator)\n",
    "        self.weights.append(1.0)\n",
    "\n",
    "        for _ in range(1, self.n_est):\n",
    "            residuals = -self.get_gradient(X, y)\n",
    "\n",
    "            model = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            model.fit(X, residuals)\n",
    "\n",
    "            self.models.append(model)\n",
    "            self.weights.append(self.learn_rate)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return 1 / (1 + np.exp(-np.sum([self.learn_rate * w * est.predict(X) for w, est in zip(self.weights, self.models)], axis=0)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = 0\n",
    "        for w, est in zip(self.weights, self.models):\n",
    "            y_pred += self.learn_rate * w * est.predict(X)\n",
    "        result =  1 / (1 + np.exp(-y_pred))\n",
    "        return (result >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5458515283842795\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.train(cx_train, cy_train)\n",
    "y_pred = model.predict(cx_test)\n",
    "accuracy = np.mean(cy_test == y_pred)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, max_depth=8, lr=0.01, n_est=1000):\n",
    "        self.max_depth = max_depth\n",
    "        self.learn_rate = lr\n",
    "        self.n_est = n_est\n",
    "        self.mean = 0\n",
    "\n",
    "    def calculate_loss(self, y_true, y_pred):\n",
    "        mse_loss = np.mean((y_true - y_pred)**2)\n",
    "        return mse_loss\n",
    "    \n",
    "    def get_residuals(self, y_true, y_pred):\n",
    "        residual = -(y_true - y_pred)\n",
    "        return residual\n",
    "    \n",
    "    def get_base_model(self, x_train, y_train):\n",
    "        model = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "        model.fit(x_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        self.models, self.losses = [], []\n",
    "        self.mean = np.mean(y_train)\n",
    "        temp = np.array([np.mean(y_train)] * len(y_train))\n",
    "        y_pred = temp.reshape(len(temp), 1)\n",
    "\n",
    "        for _ in range(self.n_est):\n",
    "            loss = self.calculate_loss(y_train, y_pred)\n",
    "            self.losses.append(loss)\n",
    "            residuals = self.get_residuals(y_train, y_pred)\n",
    "            model = self.get_base_model(x_train, residuals)\n",
    "            r = (model.predict(x_train)).reshape(len(x_train), 1)\n",
    "            y_pred -= self.learn_rate * r\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        temp = np.array([self.mean] * len(x_test))\n",
    "        y_pred = temp.reshape(len(temp), 1)\n",
    "\n",
    "        for i in range(len(self.models)):\n",
    "            temp = (self.models[i].predict(x_test)).reshape(len(x_test), 1)\n",
    "            y_pred -= self.learn_rate * temp\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  9.813387374734722\n",
      "r2 score:  0.8853316152885441\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.train(rx_train, ry_train)\n",
    "y_pred = model.predict(rx_test)\n",
    "print('mse: ', mean_squared_error(ry_test, y_pred))\n",
    "print('r2 score: ', r2_score(ry_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n, attr, num=30, stub_depth=1):\n",
    "        self.n = n\n",
    "        self.attr = attr\n",
    "        self.num = num\n",
    "        self.stub_depth = stub_depth\n",
    "\n",
    "        self.weights = np.ones(n) / n\n",
    "        self.trees, self.alphas = [], []\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        predicted = np.empty((self.n, self.num))\n",
    "        \n",
    "        for t in range(self.num):\n",
    "            self.model = DecisionTreeClassifier(max_depth=self.stub_depth)\n",
    "            self.model.fit(x_train, y_train, sample_weight=self.weights)\n",
    "            y_pred = self.model.predict(x_train)\n",
    "\n",
    "            epsilon = np.sum(self.weights * (y_pred != y_train)) / np.sum(self.weights)\n",
    "            alpha = np.log((1-epsilon) / epsilon)\n",
    "            self.weights = np.array([w*(1-epsilon)/epsilon if y_pred[i] != y_train[i] else w for i, w in enumerate(self.weights)])\n",
    "\n",
    "            self.trees.append(self.model)\n",
    "            self.alphas.append(alpha)\n",
    "            predicted[:,t] = y_pred\n",
    "        self.result = np.sign(np.dot(predicted, self.alphas))\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        y_pred = np.zeros(len(x_test))\n",
    "        for t, tree in enumerate(self.trees):\n",
    "            curr_tree = tree.predict(x_test)\n",
    "            y_pred += curr_tree*self.alphas[t]\n",
    "        return np.sign(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5589519650655022\n"
     ]
    }
   ],
   "source": [
    "n, attr = cx_train.shape\n",
    "model = AdaBoost(n, attr)\n",
    "model.fit(cx_train, cy_train)\n",
    "y_pred = model.predict(cx_test)\n",
    "accuracy = np.mean(cy_test == y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostR2:\n",
    "    def __init__(self, n, attr, num=30, stub_depth=1):\n",
    "        self.n = n\n",
    "        self.attr = attr\n",
    "        self.num = num\n",
    "        self.stub_depth = stub_depth\n",
    "\n",
    "        self.weights = np.ones(n) / n\n",
    "        self.trees, self.betas = [], []\n",
    "        self.fitted_values = np.empty((n, num))\n",
    "\n",
    "    def weighted_median(self, values, weights):\n",
    "        sorted_indices = values.argsort()\n",
    "        values = values[sorted_indices]\n",
    "        weights = weights[sorted_indices]\n",
    "        weights_cumulative_sum = weights.cumsum()\n",
    "        median_weight = np.argmax(weights_cumulative_sum >= sum(weights)/2)\n",
    "        return values[median_weight]\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        for t in range(self.num):\n",
    "            idx = np.random.choice(np.arange(self.n), size=self.n, replace=True, p=self.weights)\n",
    "            bootstrap_x, bootstrap_y = x_train[idx], y_train[idx]\n",
    "            \n",
    "            tree = DecisionTreeRegressor(max_depth=self.stub_depth)\n",
    "            tree.fit(bootstrap_x, bootstrap_y)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            y_pred = tree.predict(x_train)\n",
    "            self.fitted_values[:,t] = y_pred\n",
    "            \n",
    "            abs_error = np.abs(y_train - y_pred)\n",
    "            max_abs_error = np.max(abs_error)\n",
    "            loss_ratio = abs_error / max_abs_error\n",
    "            \n",
    "            avg_loss = np.sum(self.weights*loss_ratio)\n",
    "            if avg_loss >= 0.5:\n",
    "                self.num = t-1\n",
    "                self.fitted_values = self.fitted_values[:,:t-1]\n",
    "                self.trees = self.trees[:t-1]\n",
    "                break\n",
    "            \n",
    "            beta_t = avg_loss/(1 - avg_loss)\n",
    "            self.betas.append(beta_t)\n",
    "            \n",
    "            factor = np.sum(self.weights*beta_t**(1-loss_ratio))\n",
    "            self.weights *= beta_t**(1-loss_ratio) / factor\n",
    "            \n",
    "        self.model_weights = np.log(1 / np.array(self.betas))\n",
    "        self.pred_labels = np.array([self.weighted_median(self.fitted_values[n], self.model_weights) for n in range(self.n)])\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        k = len(x_test)\n",
    "        fitted_values = np.empty((k, self.num))\n",
    "        for t, tree in enumerate(self.trees):\n",
    "            fitted_values[:,t] = tree.predict(x_test)\n",
    "        return np.array([self.weighted_median(fitted_values[n], self.model_weights) for n in range(k)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  31.65636755151532\n",
      "r2 score:  0.6300987218429726\n"
     ]
    }
   ],
   "source": [
    "n, attr = rx_train.shape\n",
    "model = AdaBoostR2(n, attr)\n",
    "model.fit(rx_train, ry_train.squeeze())\n",
    "y_pred = model.predict(rx_test)\n",
    "print('mse: ', mean_squared_error(ry_test, y_pred))\n",
    "print('r2 score: ', r2_score(ry_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
